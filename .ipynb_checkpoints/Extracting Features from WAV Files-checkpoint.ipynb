{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defined-ottawa",
   "metadata": {},
   "source": [
    "# Extracting Features from WAV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "jewish-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import sys\n",
    "sys.path.append('/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages')\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "guilty-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample WAV file\n",
    "audio_file = 'sample_audio/debussy.wav'\n",
    "audio, sample_rate = librosa.load(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "specialized-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default frame size and hop length\n",
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-wholesale",
   "metadata": {},
   "source": [
    "## Time-Domain Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-affair",
   "metadata": {},
   "source": [
    "### Estimated Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "known-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm_audio = librosa.beat.tempo(y=audio, sr=sample_rate, hop_length=HOP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-bronze",
   "metadata": {},
   "source": [
    "### Amplitude Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dedicated-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude_envelope(signal, frame_size, hop_length):\n",
    "    return np.array([max(signal[i:(i + frame_size)]) for i in range(0, len(signal), hop_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "african-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_audio = amplitude_envelope(audio, FRAME_SIZE, HOP_SIZE)\n",
    "ae_mean = np.mean(ae_audio)\n",
    "ae_stddev = np.std(ae_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "adjustable-screen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-metallic",
   "metadata": {},
   "source": [
    "### Root-Mean Square Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ordinary-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_audio = librosa.feature.rms(audio, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "rms_mean = np.mean(rms_audio)\n",
    "rms_stddev = np.std(rms_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "empirical-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-yugoslavia",
   "metadata": {},
   "source": [
    "### Energy Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ordinary-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy(frame):\n",
    "    return np.sum(np.abs(frame)**2) / len(frame)\n",
    "\n",
    "\n",
    "def compute_frame_energy_entropy(frame, num_subframes=20):\n",
    "    subframe_size = int(np.floor(len(frame) / num_subframes))\n",
    "    subframes = [frame[i:(i + subframe_size)] for i in range(0, len(frame), subframe_size)]\n",
    "    \n",
    "    energy = np.array([compute_energy(subframe) for subframe in subframes])\n",
    "    energy = energy / np.sum(energy)\n",
    "    \n",
    "    return -np.sum(energy * np.log2(energy))\n",
    "    \n",
    "\n",
    "def energy_entropy(signal, frame_length, hop_length):\n",
    "    return np.array([compute_frame_energy_entropy(signal[i:(i + frame_length)]) for i in range(0, len(signal), hop_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "paperback-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_audio = energy_entropy(audio, FRAME_SIZE, HOP_SIZE)\n",
    "ee_mean = np.mean(ee_audio)\n",
    "ee_stddev = np.std(ee_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "turned-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-manufacturer",
   "metadata": {},
   "source": [
    "### Zero-Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "appropriate-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "zcr_audio = librosa.feature.zero_crossing_rate(audio, frame_length=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "zcr_mean = np.mean(zcr_audio)\n",
    "zcr_stddev = np.std(zcr_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "every-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcr_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-inspector",
   "metadata": {},
   "source": [
    "## Frequency-Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "associate-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spectrograms\n",
    "audio_spctgm = librosa.stft(audio, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-dealer",
   "metadata": {},
   "source": [
    "### Band-Energy Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "younger-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_FREQ = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "directed-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_frequency_bin(spectrogram, split_frequency, sample_rate):\n",
    "    frequency_range = sample_rate / 2\n",
    "    frequency_delta_per_bin = frequency_range / spectrogram.shape[0]\n",
    "    split_frequency_bin = np.floor(split_frequency / frequency_delta_per_bin)\n",
    "    return int(split_frequency_bin)\n",
    "\n",
    "\n",
    "def to_power_spectrogram(spectrogram):\n",
    "    return (np.abs(spectrogram) ** 2)\n",
    "\n",
    "\n",
    "def calculate_ber_for_frame(frequencies_in_frame, split_frequency_bin):\n",
    "    sum_power_low_freq = np.sum(frequencies_in_frame[:split_frequency_bin])\n",
    "    sum_power_high_freq = np.sum(frequencies_in_frame[split_frequency_bin:])\n",
    "    return (sum_power_low_freq / sum_power_high_freq)\n",
    "\n",
    "    \n",
    "def band_energy_ratio(spectrogram, split_frequency, sample_rate):\n",
    "    split_frequency_bin = calculate_split_frequency_bin(spectrogram, split_frequency, sample_rate)\n",
    "    power_spec = to_power_spectrogram(spectrogram).T\n",
    "    ber = [calculate_ber_for_frame(freqs_in_frame, split_frequency_bin) for freqs_in_frame in power_spec]\n",
    "    return np.array(ber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "greater-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ber_audio = band_energy_ratio(audio_spctgm, SPLIT_FREQ, sample_rate)\n",
    "ber_mean = np.mean(ber_audio)\n",
    "ber_stddev = np.std(ber_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "decreased-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-transparency",
   "metadata": {},
   "source": [
    "### Spectral Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "computational-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_audio = librosa.feature.spectral_centroid(audio, sr=sample_rate, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "sc_mean = np.mean(sc_audio)\n",
    "sc_stddev = np.std(sc_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "supreme-implement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-pixel",
   "metadata": {},
   "source": [
    "### Bandwidth / Spectral Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "contained-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_audio = librosa.feature.spectral_bandwidth(audio, sr=sample_rate, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "ss_mean = np.mean(ss_audio)\n",
    "ss_stddev = np.std(ss_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "silent-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-seeking",
   "metadata": {},
   "source": [
    "### Spectral Rolloff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "gothic-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sroll_audio = librosa.feature.spectral_rolloff(audio, sr=sample_rate, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "sroll_mean = np.mean(sroll_audio)\n",
    "sroll_stddev = np.std(sroll_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "meaningful-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sroll_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-mistake",
   "metadata": {},
   "source": [
    "### Spectral Flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "olive-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "sflat_audio = librosa.feature.spectral_flatness(audio, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "sflat_mean = np.mean(sflat_audio)\n",
    "sflat_stddev = np.std(sflat_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "optical-cycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sflat_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-tracy",
   "metadata": {},
   "source": [
    "### Spectral Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "three-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "sconstrast_audio = librosa.feature.spectral_contrast(audio, sr=sample_rate, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)[0]\n",
    "sconstrast_mean = np.mean(sconstrast_audio)\n",
    "sconstrast_stddev = np.std(sconstrast_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "blind-adobe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1292,)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sconstrast_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-scanning",
   "metadata": {},
   "source": [
    "### Spectral Flux\n",
    "\n",
    "https://www.sciencedirect.com/topics/engineering/spectral-flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "coordinated-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(spectra):\n",
    "    return spectra / np.sum(spectra)\n",
    "\n",
    "def compute_spect_flux_for_frame(prev_spectra_nmlzd, curr_spectra):\n",
    "    curr_spectra_nmlzd = normalize(curr_spectra)\n",
    "    frame_sf = np.linalg.norm(curr_spectra_nmlzd - prev_spectra_nmlzd)\n",
    "    return frame_sf, curr_spectra_nmlzd\n",
    "\n",
    "def spectral_flux(spectrogram):\n",
    "    num_frames = spectrogram.shape[1]\n",
    "    \n",
    "    curr_spectra = spectrogram[:, 0]\n",
    "    curr_spectra_nmlzd = normalize(curr_spectra)\n",
    "\n",
    "    sf = []\n",
    "    for i in range(1, num_frames):\n",
    "        frame_sf, curr_spectra_nmlzd = compute_spect_flux_for_frame(curr_spectra_nmlzd, spectrogram[:, i])\n",
    "        sf.append(frame_sf)\n",
    "        \n",
    "    return np.array(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "known-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_audio = spectral_flux(audio_spctgm)\n",
    "sf_mean = np.mean(sf_audio)\n",
    "sf_stddev = np.std(sf_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "composed-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1291,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-reset",
   "metadata": {},
   "source": [
    "## Mel-Frequency Cepstral Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "going-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs_audio = librosa.feature.mfcc(audio, n_mfcc=13, sr=sample_rate)\n",
    "mfccs_mean = np.mean(mfccs_audio, axis=1)\n",
    "mfccs_stddev = np.std(mfccs_audio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "hybrid-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1292)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs_audio.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-pursuit",
   "metadata": {},
   "source": [
    "## Chroma Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "portuguese-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_audio = librosa.feature.chroma_stft(y=audio, sr=sample_rate, n_chroma=12, \n",
    "                                           n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
    "chroma_mean = np.mean(chroma_audio, axis=1)\n",
    "chroma_stddev = np.std(chroma_audio, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "configured-worker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3427883 , 0.14246514, 0.3568891 , 0.18810047, 0.38711867,\n",
       "       0.20369092, 0.17791696, 0.53722024, 0.2640053 , 0.19303429,\n",
       "       0.13443361, 0.26362732], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-money",
   "metadata": {},
   "source": [
    "## Complete Audio Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "incorporate-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeatureExtractor():\n",
    "    MEAN = '_mean'\n",
    "    STD = '_std'\n",
    "\n",
    "    TEMPO = 'tempo'\n",
    "    TIME_DOMAIN = ['amplitude_envelope', 'energy_entropy', 'zero_crossing_rate']\n",
    "    FREQ_DOMAIN = ['band_energy_ratio', 'spectral_centroid', 'spectral_bandwidth',\n",
    "                   'spectral_rolloff', 'spectral_flatness', 'spectral_contrast',\n",
    "                   'spectral_flux']\n",
    "    MFCC = 'mfcc'\n",
    "    N_MFCC = 13\n",
    "    CHROMA = 'chroma'\n",
    "    N_CHROMA = 12\n",
    "    GENRE = 'genre'\n",
    "\n",
    "    def __init__(self, frame_size=1024, hop_length=512):\n",
    "        self.frame_size=frame_size\n",
    "        self.hop_length=hop_length\n",
    "#         self._generate_input_feature_list()\n",
    "\n",
    "#     def _generate_input_feature_list(self):\n",
    "#         self.input_features = [AudioFeatureExtractor.TEMPO]\n",
    "#         for time_feature in AudioFeatureExtractor.TIME_DOMAIN:\n",
    "#             self._append_ml_features(time_feature)\n",
    "#         for freq_feature in AudioFeatureExtractor.FREQ_DOMAIN:\n",
    "#             self._append_ml_features(freq_feature)\n",
    "#         self._append_vector_features(AudioFeatureExtractor.N_MFCC, AudioFeatureExtractor.MFCC)\n",
    "#         self._append_vector_features(AudioFeatureExtractor.N_CHROMA, AudioFeatureExtractor.CHROMA)\n",
    "#         self.input_features.append(AudioFeatureExtractor.GENRE)\n",
    "\n",
    "#     def _append_vector_features(self, n, base_feature):\n",
    "#         for i in range(1, n + 1):\n",
    "#             audio_feature = base_feature + str(i)\n",
    "#             self.input_features.append(audio_feature + AudioFeatureExtractor.MEAN)\n",
    "\n",
    "#         for i in range(1, n + 1):\n",
    "#             audio_feature = base_feature + str(i)\n",
    "#             self.input_features.append(audio_feature + AudioFeatureExtractor.MEAN)\n",
    "\n",
    "\n",
    "#     def _append_ml_features(self, audio_feature):\n",
    "#         self.input_features.append(audio_feature + AudioFeatureExtractor.MEAN)\n",
    "#         self.input_features.append(audio_feature + AudioFeatureExtractor.STD)\n",
    "\n",
    "\n",
    "    def extract(self, filename, genre):\n",
    "        signal, sr = librosa.load(filename)\n",
    "\n",
    "        tempo = self._tempo(signal, sr)\n",
    "\n",
    "        ae = self._amplitude_envelope(signal)\n",
    "        rms = self._root_mean_square_energy(signal)\n",
    "        ee = self._energy_entropy(signal)\n",
    "        zcr = self._zero_crossing_rate(signal)\n",
    "\n",
    "        spectrogram = self._extract_spectrogram(signal)\n",
    "\n",
    "        ber = self._band_energy_ratio(spectrogram, sr)\n",
    "        s_centr = self._spectral_centroid(signal, sr)\n",
    "        sb = self._spectral_bandwidth(signal, sr)\n",
    "        s_roll = self._spectral_rolloff(signal, sr)\n",
    "        s_flat = self._spectral_flatness(signal)\n",
    "        s_contr = self._spectral_contrast(signal, sr)\n",
    "        s_flux = self._spectral_flux(spectrogram)\n",
    "\n",
    "        mfcc = self._mfcc(signal, sr)\n",
    "        chroma = self._chroma(signal, sr)\n",
    "\n",
    "        vector_features = np.vstack([ae, rms, ee, zcr, ber, s_centr, sb, s_roll, s_flat, s_contr, mfcc, chroma])\n",
    "\n",
    "        means = np.mean(vector_features, axis=1)\n",
    "        std_devs = np.std(vector_features, axis=1)\n",
    "\n",
    "        return np.hstack([tempo, means, np.mean(s_flux), std_devs, np.std(s_flux), genre])\n",
    "\n",
    "### Time-Domain Features\n",
    "\n",
    "    # Tempo (beats per minute)\n",
    "    def _tempo(self, signal, sr):\n",
    "        return librosa.beat.tempo(y=signal, sr=sr, hop_length=self.hop_length)\n",
    "\n",
    "    # Amplitude Envelope\n",
    "    def _amplitude_envelope(self, signal):\n",
    "        return np.array([max(signal[i:(i + self.frame_size)]) for i in range(0, len(signal), self.hop_length)])\n",
    "\n",
    "    # Root-Mean Square Energy\n",
    "    def _root_mean_square_energy(self, signal):\n",
    "        return librosa.feature.rms(signal, frame_length=self.frame_size, hop_length=self.hop_length)[0]\n",
    "    \n",
    "    # Energy Entropy\n",
    "    def _energy_entropy(self, signal):\n",
    "        return np.array([self._compute_frame_energy_entropy(signal[i:(i + self.frame_size)]) for i in range(0, len(signal), self.hop_length)])\n",
    "\n",
    "    def _compute_frame_energy_entropy(self, frame, num_subframes=20):\n",
    "        subframe_size = int(np.floor(len(frame) / num_subframes))\n",
    "        subframes = [frame[i:(i + subframe_size)] for i in range(0, len(frame), subframe_size)]\n",
    "        \n",
    "        energy = np.array([self._compute_energy(subframe) for subframe in subframes])\n",
    "        energy = energy / np.sum(energy)\n",
    "        \n",
    "        return -np.sum(energy * np.log2(energy))\n",
    "\n",
    "    def _compute_energy(self, frame):\n",
    "        return np.sum(np.abs(frame)**2) / len(frame)\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    def _zero_crossing_rate(self, signal):\n",
    "        return librosa.feature.zero_crossing_rate(signal, frame_length=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    \n",
    "### Frequency-Domain Features\n",
    "\n",
    "    def _extract_spectrogram(self, signal):\n",
    "        return librosa.stft(signal, n_fft=self.frame_size, hop_length=self.hop_length)\n",
    "\n",
    "    # Band Energy Ratio\n",
    "    def _band_energy_ratio(self, spectrogram, sr, split_frequency=2000):\n",
    "        split_frequency_bin = self._calculate_split_frequency_bin(spectrogram, split_frequency, sr)\n",
    "        power_spec = self._to_power_spectrogram(spectrogram).T\n",
    "        return np.array([self._calculate_ber_for_frame(freqs_in_frame, split_frequency_bin) for freqs_in_frame in power_spec])\n",
    "\n",
    "    def _calculate_split_frequency_bin(self, spectrogram, split_frequency, sr):\n",
    "        frequency_range = sr / 2\n",
    "        frequency_delta_per_bin = frequency_range / spectrogram.shape[0]\n",
    "        split_frequency_bin = np.floor(split_frequency / frequency_delta_per_bin)\n",
    "        return int(split_frequency_bin)\n",
    "\n",
    "    def _to_power_spectrogram(self, spectrogram):\n",
    "        return (np.abs(spectrogram) ** 2)\n",
    "\n",
    "    def _calculate_ber_for_frame(self, frequencies_in_frame, split_frequency_bin):\n",
    "        sum_power_low_freq = np.sum(frequencies_in_frame[:split_frequency_bin])\n",
    "        sum_power_high_freq = np.sum(frequencies_in_frame[split_frequency_bin:])\n",
    "        return (sum_power_low_freq / sum_power_high_freq)\n",
    "\n",
    "    # Spectral Centroid\n",
    "    def _spectral_centroid(self, signal, sr):\n",
    "        return librosa.feature.spectral_centroid(signal, sr=sr, n_fft=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    # Spectral Bandwidth\n",
    "    def _spectral_bandwidth(self, signal, sr):\n",
    "        return librosa.feature.spectral_bandwidth(signal, sr=sr, n_fft=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    # Spectral Rolloff\n",
    "    def _spectral_rolloff(self, signal, sr):\n",
    "        return librosa.feature.spectral_rolloff(signal, sr=sr, n_fft=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    # Spectral Flatness\n",
    "    def _spectral_flatness(self, signal):\n",
    "        return librosa.feature.spectral_flatness(signal, n_fft=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    # Spectral Contrast\n",
    "    def _spectral_contrast(self, signal, sr):\n",
    "        return librosa.feature.spectral_contrast(signal, sr=sr, n_fft=self.frame_size, hop_length=self.hop_length)[0]\n",
    "\n",
    "    # Spectral Flux\n",
    "    def _spectral_flux(self, spectrogram):\n",
    "        num_frames = spectrogram.shape[1]\n",
    "        curr_spectra = spectrogram[:, 0]\n",
    "        curr_spectra_nmlzd = self._normalize(curr_spectra)\n",
    "\n",
    "        sf = []\n",
    "        for i in range(1, num_frames):\n",
    "            frame_sf, curr_spectra_nmlzd = self._compute_spect_flux_for_frame(curr_spectra_nmlzd, spectrogram[:, i])\n",
    "            sf.append(frame_sf)\n",
    "            \n",
    "        return np.array(sf)\n",
    "\n",
    "    def _normalize(self, spectra):\n",
    "        return spectra / np.sum(spectra)\n",
    "\n",
    "    def _compute_spect_flux_for_frame(self, prev_spectra_nmlzd, curr_spectra):\n",
    "        curr_spectra_nmlzd = self._normalize(curr_spectra)\n",
    "        frame_sf = np.linalg.norm(curr_spectra_nmlzd - prev_spectra_nmlzd)\n",
    "        return frame_sf, curr_spectra_nmlzd\n",
    "\n",
    "### Mel-Frequency Cepstral Coefficients\n",
    "    def _mfcc(self, signal, sr):\n",
    "        return librosa.feature.mfcc(signal, n_mfcc=AudioFeatureExtractor.N_MFCC, sr=sr)\n",
    "\n",
    "### Chroma Vector\n",
    "    def _chroma(self, signal, sr):\n",
    "        return librosa.feature.chroma_stft(signal, n_chroma=AudioFeatureExtractor.N_CHROMA, sr=sr, n_fft=self.frame_size, hop_length=self.hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "grateful-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feature_extractor = AudioFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "amateur-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = audio_feature_extractor.extract(audio_file, genre='Classical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "destroyed-underwear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-palace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
